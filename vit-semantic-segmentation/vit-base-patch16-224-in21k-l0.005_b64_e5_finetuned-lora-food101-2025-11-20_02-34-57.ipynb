{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "L4",
      "collapsed_sections": [
        "Tpt24zUEk9Ad",
        "zkklFZzPQ6dH",
        "Q3N29FeiR0sr"
      ],
      "authorship_tag": "ABX9TyNoQDcRTVAU5pZ7jVuIaq5n",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yvesemmanuel/deep-learning/blob/main/vit-semantic-segmentation/vit-base-patch16-224-in21k-l0.005_b64_e5_finetuned-lora-food101-2025-11-20_02-34-57.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import logging\n",
        "import sys\n",
        "\n",
        "logger = logging.getLogger(__name__)\n",
        "logger.setLevel(logging.INFO)\n",
        "\n",
        "logger.handlers.clear()\n",
        "logger.propagate = False\n",
        "\n",
        "handler = logging.StreamHandler(sys.stdout)\n",
        "handler.setLevel(logging.INFO)\n",
        "formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')\n",
        "handler.setFormatter(formatter)\n",
        "\n",
        "logger.addHandler(handler)\n",
        "\n",
        "logger.info(\"Logger is working!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "50cPQT2XNskF",
        "outputId": "77c4c23a-d3f3-460d-a655-6927f1c7af68"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-11-20 02:33:15,672 - INFO - Logger is working!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "O60YJAfjKCAd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "30b269c0-e097-45ae-d386-1dfa5b771b9e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/173.4 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m173.4/173.4 kB\u001b[0m \u001b[31m15.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/84.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "gcsfs 2025.3.0 requires fsspec==2025.3.0, but you have fsspec 2023.9.2 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install transformers accelerate evaluate datasets peft wandb fsspec==2023.9.2 -q"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# HuggingFace and Weights and Biases"
      ],
      "metadata": {
        "id": "Tpt24zUEk9Ad"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import notebook_login\n",
        "notebook_login()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359,
          "referenced_widgets": [
            "6323aad705104460989f6e3aec36ee11",
            "b4e0c9e51b1c42ceb6af575bb563f198",
            "8a58a01df377481c9d24876c1ca0b512",
            "755eaaeb5ec34487bc65bb0bbd385336",
            "6dff5d6e9dbf425b9997b607e0da0773",
            "2c6ab23a8c6748c080487e48c3030b5c",
            "4572c6d69bdc43a6b67dc2aaee2c5bbe",
            "3355914b3c504d5c81e513eb7b6dffbf",
            "74488f6ee41e458cbafedf2b9de2fd84",
            "e05caca9962e4e318958c8d0c88aa75a",
            "a7e31479ed224f7fbb7ef8422fd39c9e",
            "b3e6894faeeb4b04a7c7fee6b8f18af7",
            "34cf6232307e4bf595eaf1743d1368ea",
            "fd79673d698549d691d88ee47dc14c9d",
            "541682594ae245509a3d8839092e3330",
            "a3260451729241d9958117eacf3992b7",
            "0ef0fc182b3c4f0e9cfff71e197f5c4c"
          ]
        },
        "id": "trBKjTwhKHYi",
        "outputId": "027d5659-c8dd-4a41-ae59-9214bae32f87"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6323aad705104460989f6e3aec36ee11"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import wandb\n",
        "wandb.login()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OxrlsAH-k707",
        "outputId": "f0ddfd6e-b042-4ac5-8501-e21cab660371"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/notebook/notebookapp.py:191: SyntaxWarning: invalid escape sequence '\\/'\n",
            "  | |_| | '_ \\/ _` / _` |  _/ -_)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter:"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " ··········\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: No netrc file found, creating one.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33myveemmanuel\u001b[0m (\u001b[33memmanuel-company\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_checkpoint = \"google/vit-base-patch16-224-in21k\"\n",
        "dataset_id = \"food101\""
      ],
      "metadata": {
        "id": "brSYsVxhRP8o"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load dataset\n",
        "\n",
        "\n",
        "\n",
        "> This dataset consists of 101 food categories, with 101'000 images. For each class, 250 manually reviewed test images are provided as well as 750 training images. [Read more](https://huggingface.co/datasets/ethz/food101).\n",
        "\n"
      ],
      "metadata": {
        "id": "eop6VRe_QNem"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "dataset = load_dataset(dataset_id)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 465,
          "referenced_widgets": [
            "865239e369a14d669484ccecdced7596",
            "42647ba3e5624e0c858de86057039a27",
            "4449dd9719354013a6d8c7efc76b9bc3",
            "3da40f8450c74072b30a0c1271fc412e",
            "54b4b80994fb49049927cc5dfdcb3ce9",
            "16761b6c4850416f9b1f9c15886d7195",
            "dfdeb6e0e0814627a96ca04f101c4ae7",
            "fd5e4494bc164c50b8c3a18edc758dc1",
            "b230367ea7c84c259c882ac517737835",
            "3d96f632f9e44849b7e60b096b16e980",
            "69629bb873f7462f81992b0a2832d6c0",
            "68cda0d7081046fdb6f7ea6cddc9e1bf",
            "d2b2d321c5dc44c795d3a0d0482251e0",
            "4813e08ca7b44005830f6291e15d746b",
            "bd66f53c595d4d578b6369676e446f36",
            "104979e128d54e6c9ea558f944e0eca1",
            "aca6b006d7c94d6dad83f5490de3e3c4",
            "3b046d9c4a3247b58a00f8f4cc83ed7d",
            "9ff706b578d44688ad019f4a8d3610b8",
            "0b4ca876d4f94dddb8095e5b8650e6ac",
            "e2ad0eb804a14cf2ba15e9b88bd9b68b",
            "ddcff3ab0a084d21bd6dca026cdaccd2",
            "eb16e51d881b4041a021ac0cb388a00e",
            "68261a12ddf34c3fbc0ff766dbb20bc6",
            "2f4eb0cb24fa4a15ab64774250031f30",
            "8da2461f13b142e88c7a6ac760fb08eb",
            "ea6e2b8ed1e64d4d91024bd69bf70d80",
            "a28e95cc654b43429abb5cf5649c3e31",
            "5bcdc8ddcb3f46299a2dff9aa6b3a3ac",
            "d193a4125d904cb3a4270c85134e8f0b",
            "06d2ecfb05404d018f1554014b46f778",
            "105db9e79b6843d1a05d8c2af55d927e",
            "572a1d1e4edf464fa9fa4b9320c26319",
            "888c4df9729b471ca9b9f34df0f64e9b",
            "6a3438bf0e8644f7bb96dfab6de39754",
            "ed5f749e0b8647688237c51d70da2b1b",
            "d010232067e84de89357466c3af7d0ca",
            "b382d991a03346f1bf6526718a993d6f",
            "0524e432deed41afa8b452181d2aa06d",
            "297f3b190eab4b8d81f1a7ebdc0b9638",
            "7bc675e32b6c40e584df891fa723744e",
            "c7fa92b69410471bbae03c4d17e6b5f9",
            "9a98533e6b53423abeb3167d14d62911",
            "8c20f163a340463580a4e1cfdd2ea5df",
            "4fc5e4d8562a4cbab554fdf0a16a3343",
            "20a7cb9eb9ec4b4abe64c0ed2b433421",
            "e3472e8d73d141d4b875343cf8d0b1a4",
            "7d98818b7aff448b8537d20876ecc286",
            "934ef1342e2d489ba5433759537ca639",
            "2692b8945c724ca3b87856f834e1bcc6",
            "9243840ad83a4b889abdfd73cb418ef3",
            "58ab731418b8401c8b68c33afa10d5fd",
            "e52377781b004a24a9040a6096f8b246",
            "76303b142e6b408a9e31172ba9b4e4de",
            "48eb40e6dc5c4fa0b9173f92fd10c90c",
            "70ce0d7649c94a2b96d6e5e32caa1266",
            "2fa6857f4ec849ff8449d39d33dfab59",
            "333c0f179fab46f2be6067549545ccab",
            "979f52edecca42d5a8324b7115afc9a7",
            "90466c0f91a54627a97186a6b1a7fabb",
            "8b041e2f2f4f4ba3b06c9fe209c2ee4f",
            "5971759dd977444698dc66bdf971e9ae",
            "51751436e8e442ae9289202ae92359fc",
            "7c461d2c5e2b4fabaca5df52086e2d2b",
            "27cce4fcbf324a62b46a4e93fc5faec6",
            "c002097a7ab9414a946516c16a393d00",
            "38a0f0a7c30a42e488542908ad068831",
            "87ba7be550e44e85b44c52956af6e74d",
            "f496b387c3f34de993535eeace7ef796",
            "96bb46f36ccb40939152aea6c4bea4ab",
            "f36131bc0eb64481b437f951459fbc38",
            "2bc9fd20e8c54c069336b0556c0109fc",
            "2e3f6f1a52ac46f1a9474b45b0e21c5c",
            "09f08777ab61472ebfba3fb0844e13c5",
            "0fd740e58c6140c0ad52fbe0c2c21a23",
            "b2da774418814f6fb6fd8ae6e201abc1",
            "1bdca0b0f76d42da9530adfcf8a4cd06",
            "5f6b5ca79d7d45e59148255d805793e8",
            "0b238fc942d3437a91afa3ff445b6280",
            "11d8c17e45d24ead80eae61d4fc5d245",
            "93bdd8ceaab347ef8c42762387e4854b",
            "325e3e6f9c7045d2b1f508f8c894a8f5",
            "0aa4959655ca47128008bd0ce5502333",
            "0ad5c8c949294d8f82fe09292da49a65",
            "6a5b6378793c40c0b00e81c874f12566",
            "726304f8f1174f439c52f235c8f64c10",
            "6fafeba7046d4222a63fc5468f56be0c",
            "0a8dca3959234bfb96788a1fbbe51abd",
            "7b28e8a829aa4eefb3465372a0f86774",
            "d352c0be9c7e4c7d88597e96cce7c664",
            "ed2e00c31b144c4ea8bcc56ec37b06f4",
            "cc5e108474e54b218ae1538a9dbd39ec",
            "1d8a2fb0ae044bff90c43802a11e6e7b",
            "9f4ccfeea1084c2aa565b57ca7791c41",
            "925cca33ff6d4f80896dfc8a30e2509e",
            "0121cc940cd14ed6ab6272f54aec176d",
            "93fc2e43861d491c9847833047811d07",
            "613a3406429940f0be0a027e1c16a17a",
            "c9b9e8cb425843bbba484cdbd96b6ecf",
            "bffde46ed8b948f7b312e83167ade749",
            "e847615d6d5a42adbd4148c4f5e7b18e",
            "dbf26ed76c454aa5bcc4326391169ba1",
            "0b239f805b8d4a76b45a0697449c1afb",
            "598e4f1e22794b6c93850b60c623a8d0",
            "8bd5065ee9f240d08c2021c08856625c",
            "5e489601b54f42028087a2edd3e7e111",
            "5e524c90714e4ebfa6895a42f02e1f2b",
            "cb43515c14684605b2eda5f0e44646b7",
            "5686f172b2b8426b848418d416af0730",
            "4e43254c90384f9aacaf4f200131154e",
            "4bd0825802594d8d95be3d2a635dd080",
            "73c83a48002247739f701e782c511326",
            "8927513fc9704e31967b936f54929737",
            "946e6f8796794918b237ef76b4ee40ad",
            "3ce650333aa34f20b3954db971add341",
            "ebbe7d4b2096428e9c2aa68c8a8c831c",
            "e86085beabaa41b483b9f04a54b947c0",
            "8358ae9b5b6e4a96a6d893771a8e2863",
            "e48e783378194a3e9685a416a9808115",
            "0b6c39498207473b81a1088cdbd01ef8",
            "8c1f937cd32b483fa18c313ab2101033",
            "7380647920d8435d927cadbf7d518e48",
            "605d323214ec46148f30997d8d40c33d",
            "078c1d843a274aa8be1f08b3b46f0829",
            "b2f1fd366c1a4afdba09528021e64cf1",
            "78c5d5ccfd1c4ac391dc958a8c3742d3",
            "4ac8239409624054a3962b0a2f8d358c",
            "de2c8c5d40cf4825985f71be9b04adfc",
            "0e205380539c4af89aa1c2b5f6debdfc",
            "214916721f51417a8fba6018771b5d2f",
            "a6449d768d0f4e6ab79a7923a63e7958",
            "1faa288e8c884334b3689eca4ea27330",
            "52874db30d544253a4fbc1772ebfd223",
            "a0a5dc2abe304e2daab42c6396e03c94",
            "8b53af16117f4fa28a09727ae0fd777a",
            "a36f61cae3e84ddab80584ce2bc1ad2e",
            "5524f5171f5345b7b51fc3ccd217e0c2",
            "055a982b585945178aaa967863fae1f1",
            "99e1f0d26c0744fd9acd66e24c49d8b6",
            "a47d34edb3004605b27cb2fc1a7eb06d",
            "20396c0c22ec4c328d3af5b8c793e4e6",
            "3a4b3aae1d704b87a1534c82d2d3697e",
            "bb977fbfb987404f8e8e2127e138a0ac",
            "a8e0cd5f282f4c3c9922e6d656be5633",
            "54cc136fa4474567ad2372e7c83e4ca9",
            "d8ff3ed6f9f647c18ef3518a8648e455",
            "5386bd1522e54fba90343adbc2cc5af6",
            "500ce397ae4d46e88d4cabafbaa8f19a",
            "0a515bd133294f31a5f981018acb15ad",
            "e37cbad193974d09978e32e1773d2c02",
            "1268021b63f5494eb8a0aabb2b6431b7",
            "1de15d93da69443f818fea3148122754",
            "7edcb2e17c0645e394528997f30b9db8",
            "7e9acfafed8d499e9063e0c25288c2a1"
          ]
        },
        "id": "PJQD4aeoKISb",
        "outputId": "d6ff9d5d-4fd5-450a-cfd8-0feb022217da"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "README.md: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "865239e369a14d669484ccecdced7596"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "data/train-00000-of-00008.parquet:   0%|          | 0.00/490M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "68cda0d7081046fdb6f7ea6cddc9e1bf"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "data/train-00001-of-00008.parquet:   0%|          | 0.00/464M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "eb16e51d881b4041a021ac0cb388a00e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "data/train-00002-of-00008.parquet:   0%|          | 0.00/472M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "888c4df9729b471ca9b9f34df0f64e9b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "data/train-00003-of-00008.parquet:   0%|          | 0.00/464M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4fc5e4d8562a4cbab554fdf0a16a3343"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "data/train-00004-of-00008.parquet:   0%|          | 0.00/475M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "70ce0d7649c94a2b96d6e5e32caa1266"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "data/train-00005-of-00008.parquet:   0%|          | 0.00/470M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "38a0f0a7c30a42e488542908ad068831"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "data/train-00006-of-00008.parquet:   0%|          | 0.00/478M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5f6b5ca79d7d45e59148255d805793e8"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "data/train-00007-of-00008.parquet:   0%|          | 0.00/486M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7b28e8a829aa4eefb3465372a0f86774"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "data/validation-00000-of-00003.parquet:   0%|          | 0.00/423M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "bffde46ed8b948f7b312e83167ade749"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "data/validation-00001-of-00003.parquet:   0%|          | 0.00/413M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4bd0825802594d8d95be3d2a635dd080"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "data/validation-00002-of-00003.parquet:   0%|          | 0.00/426M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7380647920d8435d927cadbf7d518e48"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating train split:   0%|          | 0/75750 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "52874db30d544253a4fbc1772ebfd223"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating validation split:   0%|          | 0/25250 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a8e0cd5f282f4c3c9922e6d656be5633"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preprocessing dataset\n",
        "\n",
        "This includes:\n",
        "\n",
        "*   Labels mapping;\n",
        "*   Data splitting;\n",
        "*   Data normalization;\n",
        "*   Data training augmentation."
      ],
      "metadata": {
        "id": "Ca4OQme4QUwm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Label-to-ID mapping"
      ],
      "metadata": {
        "id": "UBdfkvODfbw-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s920nONMn8SY",
        "outputId": "48c23e93-620b-4d5c-ce86-9101279635ec"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['image', 'label'],\n",
              "        num_rows: 75750\n",
              "    })\n",
              "    validation: Dataset({\n",
              "        features: ['image', 'label'],\n",
              "        num_rows: 25250\n",
              "    })\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lxcSk7s5oCBz",
        "outputId": "25416481-197c-43ad-c234-7c56b959165a"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['image', 'label'],\n",
              "        num_rows: 75750\n",
              "    })\n",
              "    validation: Dataset({\n",
              "        features: ['image', 'label'],\n",
              "        num_rows: 25250\n",
              "    })\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "labels = dataset[\"train\"].features[\"label\"].names\n",
        "label2id, id2label = dict(), dict()\n",
        "for i, label in enumerate(labels):\n",
        "  label2id[label] = i\n",
        "  id2label[i] = label"
      ],
      "metadata": {
        "id": "T2m6DYxRQUVA"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "id2label[2]"
      ],
      "metadata": {
        "id": "nLnxRbmkQYHL",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "10963204-49f8-4199-bc16-635d81840d5a"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'baklava'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Image processor"
      ],
      "metadata": {
        "id": "Bz2XTDXMQk_3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoImageProcessor"
      ],
      "metadata": {
        "id": "J9FwfeFcQfjw"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_processor = AutoImageProcessor.from_pretrained(model_checkpoint)"
      ],
      "metadata": {
        "id": "ANK_383oQhGl",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118,
          "referenced_widgets": [
            "1c502115007f4474baf9a96cc6cc8eb8",
            "bd0d72040f514c9c915894bc4e18faec",
            "c73352ecf21c4b319ae7fcc8a8845406",
            "b6c51e3f35aa4b5fa6afe5b36b153fa4",
            "8100a4b870c14ce2ac0397edebd34154",
            "840dcc9b4f9b457c869e2dafcc7e00d3",
            "a31b5aedc9bd43e9a693c9f1af8d7e51",
            "a2cbc55b0f7b43d09a68f880b6649d10",
            "bc211584fde4438b9cc5a62db22f0a71",
            "11463b2d14104e73be7ede3ace7e3416",
            "427be1a075204022990b49c6f8a98873",
            "07e2f4bfc694492d9f857b3487e2b7b3",
            "d82d33b9c0a143eeb6fd154f9a436655",
            "4e4204a8d0e14c9b9d589b22fbe5bf9f",
            "af6f06f928894deb8133c609ad9e953a",
            "1b00c8c0981742e3aa66fdd455d13c85",
            "b85dbf2ed53043bb81a09931dfead55b",
            "0d1e0c06adc34a469e77dc4cc577bd26",
            "cb4bce32d1f9496d8f58f9a813bcbd92",
            "3a3508818b184174b615b32b56fde05e",
            "f2b25c52aee347c3b60a6a308735e2ce",
            "8ea21797fa444ac39d44ae70ed89363c"
          ]
        },
        "outputId": "29b7166b-f51c-4c73-f2dc-4fac3a13acb0"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "preprocessor_config.json:   0%|          | 0.00/160 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1c502115007f4474baf9a96cc6cc8eb8"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/502 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "07e2f4bfc694492d9f857b3487e2b7b3"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Fast image processor class <class 'transformers.models.vit.image_processing_vit_fast.ViTImageProcessorFast'> is available for this model. Using slow image processor class. To use the fast image processor class set `use_fast=True`.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training data augmentation & test/eval normalization"
      ],
      "metadata": {
        "id": "nDiLhPdSmyXc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision.transforms import (\n",
        "  CenterCrop,\n",
        "  Compose,\n",
        "  Normalize,\n",
        "  RandomHorizontalFlip,\n",
        "  RandomResizedCrop,\n",
        "  Resize,\n",
        "  ToTensor,\n",
        ")"
      ],
      "metadata": {
        "id": "ru9E4PMQQsHI"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "normalize = Normalize(mean=image_processor.image_mean, std=image_processor.image_std)\n",
        "train_transforms = Compose(\n",
        "  [\n",
        "      RandomResizedCrop(image_processor.size[\"height\"]),\n",
        "      RandomHorizontalFlip(),\n",
        "      ToTensor(),\n",
        "      normalize,\n",
        "  ]\n",
        ")\n",
        "\n",
        "transforms = Compose(\n",
        "  [\n",
        "      Resize(image_processor.size[\"height\"]),\n",
        "      CenterCrop(image_processor.size[\"height\"]),\n",
        "      ToTensor(),\n",
        "      normalize,\n",
        "  ]\n",
        ")\n",
        "\n",
        "\n",
        "def preprocess_train(example_batch):\n",
        "  \"\"\"Apply train_transforms across a batch.\"\"\"\n",
        "  example_batch[\"pixel_values\"] = [train_transforms(image.convert(\"RGB\")) for image in example_batch[\"image\"]]\n",
        "  return example_batch\n",
        "\n",
        "\n",
        "def preprocess(example_batch):\n",
        "  \"\"\"Apply transforms across a batch.\"\"\"\n",
        "  example_batch[\"pixel_values\"] = [transforms(image.convert(\"RGB\")) for image in example_batch[\"image\"]]\n",
        "  return example_batch"
      ],
      "metadata": {
        "id": "DCupkh9yQqxc"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data splitting\n",
        "\n",
        "Three data splits; 1) train, 2) eval, 2) test."
      ],
      "metadata": {
        "id": "OYTm9Y84m2K7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZroXoHV1o_5L",
        "outputId": "72863f59-7369-43aa-a467-b6b80482ce7c"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['image', 'label'],\n",
              "        num_rows: 75750\n",
              "    })\n",
              "    validation: Dataset({\n",
              "        features: ['image', 'label'],\n",
              "        num_rows: 25250\n",
              "    })\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = dataset[\"train\"]\n",
        "val_data = dataset[\"validation\"]\n",
        "\n",
        "val_data_split = val_data.train_test_split(test_size=0.3)\n",
        "val_data = val_data_split[\"train\"]\n",
        "test_data = val_data_split[\"test\"]"
      ],
      "metadata": {
        "id": "Du6e86xN0zvN"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data.set_transform(preprocess_train)\n",
        "val_data.set_transform(preprocess)\n",
        "test_data.set_transform(preprocess)"
      ],
      "metadata": {
        "id": "zTcOfVLIQ4QQ"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model *tunable* hyperparameters"
      ],
      "metadata": {
        "id": "zkklFZzPQ6dH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def print_trainable_parameters(model):\n",
        "  trainable_params = 0\n",
        "  all_param = 0\n",
        "  for _, param in model.named_parameters():\n",
        "      all_param += param.numel()\n",
        "      if param.requires_grad:\n",
        "          trainable_params += param.numel()\n",
        "  logger.info(\n",
        "      f\"trainable params: {trainable_params} || all params: {all_param} || trainable%: {100 * trainable_params / all_param:.2f}\"\n",
        "  )"
      ],
      "metadata": {
        "id": "BtrEGLegRDQt"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForImageClassification"
      ],
      "metadata": {
        "id": "DBYOx_z8RHmA"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = AutoModelForImageClassification.from_pretrained(\n",
        "  model_checkpoint,\n",
        "  label2id=label2id,\n",
        "  id2label=id2label,\n",
        "  ignore_mismatched_sizes=True,  # provide this in case you're planning to fine-tune an already fine-tuned checkpoint\n",
        ")"
      ],
      "metadata": {
        "id": "1H1B0FNGRDWo",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0,
          "referenced_widgets": [
            "e7fec905e4504e68899bb9229535b59b",
            "d859b9c31e9f4483ab213575be992598",
            "75571e11404b469483880fdd7f8f464d",
            "5b2e88f1a93a4259bf08865766d3e018",
            "d5da594bca6c4916ac286f812576c549",
            "fd08356c8f49431e928f25788bb765f3",
            "e4059838317549b9b1578b55804f5b42",
            "5ec51b78803b44b9914911fe136a2360",
            "319f56851e6041039981e0f5194a2ff2",
            "08cdb63ac5c94d17aef7fec3c9eefb2e",
            "00472a401d714aa3b69ab928c0cc9a28"
          ]
        },
        "outputId": "ce61f0dd-713b-471f-b6e9-85066a02231d"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/346M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e7fec905e4504e68899bb9229535b59b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of ViTForImageClassification were not initialized from the model checkpoint at google/vit-base-patch16-224-in21k and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print_trainable_parameters(model)"
      ],
      "metadata": {
        "id": "cxlpbrZgRdHY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e01b4304-86e8-4d0d-e910-700a4b0539c2"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-11-20 02:34:56,543 - INFO - trainable params: 85876325 || all params: 85876325 || trainable%: 100.00\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Low-Rank Adaptation"
      ],
      "metadata": {
        "id": "Q3N29FeiR0sr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from peft import LoraConfig, get_peft_model"
      ],
      "metadata": {
        "id": "rhcJX_gAg93G"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lora_config = LoraConfig(\n",
        "  r=32,\n",
        "  lora_alpha=16,\n",
        "  target_modules=[\"query\", \"value\"],\n",
        "  lora_dropout=0.1,\n",
        "  bias=\"none\",\n",
        "  modules_to_save=[\"classifier\"],\n",
        ")\n",
        "lora_model = get_peft_model(model, lora_config)"
      ],
      "metadata": {
        "id": "G5bcGByxR2kC"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print_trainable_parameters(lora_model)"
      ],
      "metadata": {
        "id": "Knzmsu57R7Bm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "453d3eac-28cd-4bf4-cc94-2e34393e030f"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-11-20 02:34:56,959 - INFO - trainable params: 1257317 || all params: 87133642 || trainable%: 1.44\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training"
      ],
      "metadata": {
        "id": "9j-X7K_2R9fc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import TrainingArguments\n",
        "import datetime"
      ],
      "metadata": {
        "id": "N6hIkhZ0SVmq"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import datetime"
      ],
      "metadata": {
        "id": "DBJhyt5OlYxi"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = model_checkpoint.split(\"/\")[-1]\n",
        "batch_size = 64\n",
        "learning_rate = 5e-3\n",
        "num_train_epochs = 5\n",
        "logging_steps = 10\n",
        "\n",
        "timestamp = datetime.datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
        "run_name = f\"{model_name}-l{learning_rate}_b{batch_size}_e{num_train_epochs}_finetuned-lora-{dataset_id}-{timestamp}\"\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "  remove_unused_columns=False,\n",
        "  eval_strategy=\"epoch\",\n",
        "  save_strategy=\"epoch\",\n",
        "  learning_rate=learning_rate,\n",
        "  per_device_train_batch_size=batch_size,\n",
        "  gradient_accumulation_steps=4,\n",
        "  per_device_eval_batch_size=batch_size,\n",
        "  fp16=True,\n",
        "  num_train_epochs=num_train_epochs,\n",
        "  logging_steps=logging_steps,\n",
        "  load_best_model_at_end=True,\n",
        "  metric_for_best_model=\"accuracy\",\n",
        "  push_to_hub=True,\n",
        "  label_names=[\"labels\"],\n",
        "  run_name=run_name,\n",
        "  report_to=[\"wandb\"]\n",
        ")"
      ],
      "metadata": {
        "id": "gVZpYV7bR-zL"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluation metrics"
      ],
      "metadata": {
        "id": "QVyarVFfSSNe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import evaluate"
      ],
      "metadata": {
        "id": "8veocBOEST3N"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "metric = evaluate.load(\"accuracy\")\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "  \"\"\"Computes accuracy on a batch of predictions\"\"\"\n",
        "  predictions = np.argmax(eval_pred.predictions, axis=1)\n",
        "  return metric.compute(predictions=predictions, references=eval_pred.label_ids)"
      ],
      "metadata": {
        "id": "ub1AioLDSPXP",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "c59a80d9f0a74a3ea48cbb57ac6b530c",
            "32d416f00fe648ac9974c67aa4867495",
            "e0f6f6b06f1c4e09ab9411473ed32e1c",
            "142f35c69d824f3a89ab75ea863efda9",
            "c66dc234dc9e4c9285fb379153241b32",
            "6acfc86ff57a4720a9bd1102ae58ae70",
            "d58217f9b6a24837903721c519839113",
            "3e18ca8c36cb41ba90ef59dd0751b416",
            "d84e3ef542604161bda2608480efd82e",
            "99bf66e4cf354ad188655cbd7ef8ad01",
            "170dd501d3bf418bbf230e7ec3d92852"
          ]
        },
        "outputId": "7f63361c-19bd-419b-f081-6aab297b351b"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading builder script: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c59a80d9f0a74a3ea48cbb57ac6b530c"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data collaction function\n",
        "\n",
        "> A collation function is used by Trainer to gather a batch of training and evaluation examples and prepare them in a format that is acceptable by the underlying model. [Read more](https://huggingface.co/docs/transformers/main/en/main_classes/trainer#transformers.Trainer).\n"
      ],
      "metadata": {
        "id": "nthmx4VsSlDN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch"
      ],
      "metadata": {
        "id": "nnwfk96RSgQc"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def collate_fn(examples):\n",
        "  pixel_values = torch.stack([example[\"pixel_values\"] for example in examples])\n",
        "  labels = torch.tensor([example[\"label\"] for example in examples])\n",
        "  return {\"pixel_values\": pixel_values, \"labels\": labels}"
      ],
      "metadata": {
        "id": "EBPR9c4LSkun"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training steps"
      ],
      "metadata": {
        "id": "9npE7jE5SqkX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import Trainer"
      ],
      "metadata": {
        "id": "yaOSfMU6Ss51"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer = Trainer(\n",
        "  lora_model,\n",
        "  training_args,\n",
        "  train_dataset=train_data,\n",
        "  eval_dataset=val_data,\n",
        "  tokenizer=image_processor,\n",
        "  compute_metrics=compute_metrics,\n",
        "  data_collator=collate_fn,\n",
        ")\n",
        "train_results = trainer.train()"
      ],
      "metadata": {
        "id": "u6VIQns5SrVs",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 547
        },
        "outputId": "f5a03007-a898-42c6-8a54-8f30283223ac"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-347704202.py:1: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = Trainer(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.22.3"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20251120_023501-ppf670zf</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/emmanuel-company/huggingface/runs/ppf670zf' target=\"_blank\">revived-puddle-5</a></strong> to <a href='https://wandb.ai/emmanuel-company/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/emmanuel-company/huggingface' target=\"_blank\">https://wandb.ai/emmanuel-company/huggingface</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/emmanuel-company/huggingface/runs/ppf670zf' target=\"_blank\">https://wandb.ai/emmanuel-company/huggingface/runs/ppf670zf</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1480' max='1480' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1480/1480 1:00:17, Epoch 5/5]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.864800</td>\n",
              "      <td>0.482838</td>\n",
              "      <td>0.863423</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.754200</td>\n",
              "      <td>0.420630</td>\n",
              "      <td>0.881810</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.654400</td>\n",
              "      <td>0.377245</td>\n",
              "      <td>0.889109</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.549200</td>\n",
              "      <td>0.349105</td>\n",
              "      <td>0.899463</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.484600</td>\n",
              "      <td>0.332042</td>\n",
              "      <td>0.904781</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/PIL/TiffImagePlugin.py:950: UserWarning: Truncated File Read\n",
            "  warnings.warn(str(msg))\n",
            "/usr/local/lib/python3.12/dist-packages/PIL/TiffImagePlugin.py:950: UserWarning: Truncated File Read\n",
            "  warnings.warn(str(msg))\n",
            "/usr/local/lib/python3.12/dist-packages/PIL/TiffImagePlugin.py:950: UserWarning: Truncated File Read\n",
            "  warnings.warn(str(msg))\n",
            "/usr/local/lib/python3.12/dist-packages/PIL/TiffImagePlugin.py:950: UserWarning: Truncated File Read\n",
            "  warnings.warn(str(msg))\n",
            "/usr/local/lib/python3.12/dist-packages/PIL/TiffImagePlugin.py:950: UserWarning: Truncated File Read\n",
            "  warnings.warn(str(msg))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "nOIEzGYUTIoT"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluate metrics on test - unseen - dataset\n",
        "\n",
        "Results from training, system usage and evaluation will be in the dashboard of Weights and Biases. [Read more](https://wandb.ai/emmanuel-company/huggingface/runs/ppf670zf?nw=nwuseryveemmanuel)."
      ],
      "metadata": {
        "id": "cNCmttmBSvwG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.evaluate(test_data)"
      ],
      "metadata": {
        "id": "10fcKv0VSwf3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176
        },
        "outputId": "63486922-bce0-400b-fb19-91817aff96a5"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='119' max='119' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [119/119 00:45]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/PIL/TiffImagePlugin.py:950: UserWarning: Truncated File Read\n",
            "  warnings.warn(str(msg))\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'eval_loss': 0.3286559283733368,\n",
              " 'eval_accuracy': 0.905082508250825,\n",
              " 'eval_runtime': 46.0502,\n",
              " 'eval_samples_per_second': 164.494,\n",
              " 'eval_steps_per_second': 2.584,\n",
              " 'epoch': 5.0}"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "wandb.finish()"
      ],
      "metadata": {
        "id": "RHrARlc24E7m",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 722
        },
        "outputId": "c062be99-d5d7-4a82-b2d1-5bdf9ede00e8"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>▁▄▅▇██</td></tr><tr><td>eval/loss</td><td>█▅▃▂▁▁</td></tr><tr><td>eval/runtime</td><td>█████▁</td></tr><tr><td>eval/samples_per_second</td><td>█▁▇▇▂▃</td></tr><tr><td>eval/steps_per_second</td><td>█▁▇▇▂▄</td></tr><tr><td>train/epoch</td><td>▁▁▁▁▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇█</td></tr><tr><td>train/global_step</td><td>▁▁▁▁▁▂▂▂▂▂▃▃▃▄▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇████</td></tr><tr><td>train/grad_norm</td><td>▁▂▁▂▂▂▂█▂▂▂▂▂▂▄▂▂▂▁▂▂▁▂▁▁▁▂▁▁▂▂▁▁▂▁▂▂▂▂▂</td></tr><tr><td>train/learning_rate</td><td>█████▇▇▇▆▆▆▆▆▆▆▅▅▅▅▅▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▂▁▁▁▁</td></tr><tr><td>train/loss</td><td>█▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>0.90508</td></tr><tr><td>eval/loss</td><td>0.32866</td></tr><tr><td>eval/runtime</td><td>46.0502</td></tr><tr><td>eval/samples_per_second</td><td>164.494</td></tr><tr><td>eval/steps_per_second</td><td>2.584</td></tr><tr><td>total_flos</td><td>2.980623013111296e+19</td></tr><tr><td>train/epoch</td><td>5</td></tr><tr><td>train/global_step</td><td>1480</td></tr><tr><td>train/grad_norm</td><td>0.48246</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>+5</td><td>...</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">revived-puddle-5</strong> at: <a href='https://wandb.ai/emmanuel-company/huggingface/runs/ppf670zf' target=\"_blank\">https://wandb.ai/emmanuel-company/huggingface/runs/ppf670zf</a><br> View project at: <a href='https://wandb.ai/emmanuel-company/huggingface' target=\"_blank\">https://wandb.ai/emmanuel-company/huggingface</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20251120_023501-ppf670zf/logs</code>"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}