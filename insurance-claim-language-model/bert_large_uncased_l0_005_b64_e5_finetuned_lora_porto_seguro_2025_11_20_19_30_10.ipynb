{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yvesemmanuel/deep-learning/blob/main/insurance-claim-language-model/bert_large_uncased_l0_005_b64_e5_finetuned_lora_porto_seguro_2025_11_20_19_30_10.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "efc12632",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "efc12632",
        "outputId": "65c9a904-2aa1-4d9f-cb76-6b0d22be86ad"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-11-20 19:27:32,874 - INFO - Logger is working!\n"
          ]
        }
      ],
      "source": [
        "import logging\n",
        "import sys\n",
        "\n",
        "logger = logging.getLogger(__name__)\n",
        "logger.setLevel(logging.INFO)\n",
        "\n",
        "logger.handlers.clear()\n",
        "logger.propagate = False\n",
        "\n",
        "handler = logging.StreamHandler(sys.stdout)\n",
        "handler.setLevel(logging.INFO)\n",
        "formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')\n",
        "handler.setFormatter(formatter)\n",
        "\n",
        "logger.addHandler(handler)\n",
        "\n",
        "logger.info(\"Logger is working!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "46293224",
      "metadata": {
        "id": "46293224"
      },
      "outputs": [],
      "source": [
        "!pip install transformers accelerate evaluate datasets peft wandb fsspec==2023.9.2 -q"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import random\n",
        "import os\n",
        "\n",
        "SEED = 42\n",
        "\n",
        "def set_universal_seed(seed_value):\n",
        "    \"\"\"Sets the seed for full reproducibility across Python, NumPy, and PyTorch.\"\"\"\n",
        "    random.seed(seed_value)\n",
        "    os.environ[\"PYTHONHASHSEED\"] = str(seed_value)\n",
        "    np.random.seed(seed_value)\n",
        "    torch.manual_seed(seed_value)\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.manual_seed(seed_value)\n",
        "        torch.cuda.manual_seed_all(seed_value) # for multi-GPU\n",
        "\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "\n",
        "set_universal_seed(SEED)"
      ],
      "metadata": {
        "id": "DP3SchKjg4Dx"
      },
      "id": "DP3SchKjg4Dx",
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "bae0d469",
      "metadata": {
        "id": "bae0d469"
      },
      "source": [
        "# HuggingFace and Weights and Biases"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "3a82475e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 415,
          "referenced_widgets": [
            "07a5a53f6d3f4ac7b50af32f6fce222a",
            "69b6cb5a96754e889d469bd03fe84bc6",
            "7867c3461f43444b841d230667a3e2e6",
            "7667324284ba4b9ebd4c534d150a763a",
            "b078aa3cddaa4712ae625e91bbc07332",
            "f8ed4190c97b41c48027a73ebb242bce",
            "d03b788dc7cc4b6197bab10e3304a56b",
            "f043d3839a154f5896369b8c631cdec8",
            "d1d712b20951428994ed2a6bd87a3074",
            "d608c963df7c4f879bf69e89b1c6508b",
            "6a72d62937ce467aa66d5eea090539ae",
            "f93ff22c23b34ed8ae5fa3410c9eab1c",
            "c084f0a44dc04dbbbbeae9c80302e03b",
            "e77cf4c6b4fd4307958b4d37b92c44d5",
            "4b7e2acd12a14ab1899029843027b742",
            "f2b68f68166a475aa4a46f165ca69cb1",
            "c5e3a1fa2d964a0e815a9e6c7b495216"
          ]
        },
        "id": "3a82475e",
        "outputId": "b682efc9-6659-4401-e7c6-d8d43a1406e0"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "07a5a53f6d3f4ac7b50af32f6fce222a"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "from huggingface_hub import notebook_login\n",
        "notebook_login()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "a0cf4aba",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a0cf4aba",
        "outputId": "6132b956-fb8e-462f-d3d8-e1514b52cef2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33myveemmanuel\u001b[0m (\u001b[33memmanuel-company\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "import wandb\n",
        "wandb.login()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "702dd19d",
      "metadata": {
        "id": "702dd19d"
      },
      "outputs": [],
      "source": [
        "model_checkpoint = \"google-bert/bert-large-uncased\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "14bd66a3",
      "metadata": {
        "id": "14bd66a3"
      },
      "source": [
        "# Load dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "876de7bb",
      "metadata": {
        "id": "876de7bb"
      },
      "outputs": [],
      "source": [
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "1ae046f4",
      "metadata": {
        "id": "1ae046f4"
      },
      "outputs": [],
      "source": [
        "dataset_id = \"porto-seguro\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_path = \"/content/train.csv\"\n",
        "ott_path = \"/content/test.csv\""
      ],
      "metadata": {
        "id": "kyu9jFu0ejG9"
      },
      "id": "kyu9jFu0ejG9",
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "4d9282ff",
      "metadata": {
        "id": "4d9282ff"
      },
      "outputs": [],
      "source": [
        "try:\n",
        "    df_raw = pd.read_csv(train_path)\n",
        "except FileNotFoundError:\n",
        "    logger.error(\"Error: 'train.csv' file not found. Please load the PortoSeguro dataset.\")\n",
        "    df_raw = pd.DataFrame({\"id\": [], \"target\": []})"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "    df_ott = pd.read_csv(ott_path)\n",
        "except FileNotFoundError:\n",
        "    logger.error(\"Error: 'test.csv' file not found. Please load the PortoSeguro dataset.\")\n",
        "    df_ott = pd.DataFrame({\"id\": [], \"target\": []})"
      ],
      "metadata": {
        "id": "8uge35L9knus"
      },
      "id": "8uge35L9knus",
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_raw.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "id": "w5hgoqeFeqJ-",
        "outputId": "488807e2-cfa2-4cb2-8bd7-a9138c2f8120"
      },
      "id": "w5hgoqeFeqJ-",
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   id  target  ps_ind_01  ps_ind_02_cat  ps_ind_03  ps_ind_04_cat  \\\n",
              "0   7       0          2              2          5              1   \n",
              "1   9       0          1              1          7              0   \n",
              "2  13       0          5              4          9              1   \n",
              "3  16       0          0              1          2              0   \n",
              "4  17       0          0              2          0              1   \n",
              "\n",
              "   ps_ind_05_cat  ps_ind_06_bin  ps_ind_07_bin  ps_ind_08_bin  ...  \\\n",
              "0              0              0              1              0  ...   \n",
              "1              0              0              0              1  ...   \n",
              "2              0              0              0              1  ...   \n",
              "3              0              1              0              0  ...   \n",
              "4              0              1              0              0  ...   \n",
              "\n",
              "   ps_calc_11  ps_calc_12  ps_calc_13  ps_calc_14  ps_calc_15_bin  \\\n",
              "0         9.0         1.0         5.0         8.0             0.0   \n",
              "1         3.0         1.0         1.0         9.0             0.0   \n",
              "2         4.0         2.0         7.0         7.0             0.0   \n",
              "3         2.0         2.0         4.0         9.0             0.0   \n",
              "4         3.0         1.0         1.0         3.0             0.0   \n",
              "\n",
              "   ps_calc_16_bin  ps_calc_17_bin  ps_calc_18_bin  ps_calc_19_bin  \\\n",
              "0             1.0             1.0             0.0             0.0   \n",
              "1             1.0             1.0             0.0             1.0   \n",
              "2             1.0             1.0             0.0             1.0   \n",
              "3             0.0             0.0             0.0             0.0   \n",
              "4             0.0             0.0             1.0             1.0   \n",
              "\n",
              "   ps_calc_20_bin  \n",
              "0             1.0  \n",
              "1             0.0  \n",
              "2             0.0  \n",
              "3             0.0  \n",
              "4             0.0  \n",
              "\n",
              "[5 rows x 59 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b9011747-06b5-432c-a1d4-8dd20128071c\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>target</th>\n",
              "      <th>ps_ind_01</th>\n",
              "      <th>ps_ind_02_cat</th>\n",
              "      <th>ps_ind_03</th>\n",
              "      <th>ps_ind_04_cat</th>\n",
              "      <th>ps_ind_05_cat</th>\n",
              "      <th>ps_ind_06_bin</th>\n",
              "      <th>ps_ind_07_bin</th>\n",
              "      <th>ps_ind_08_bin</th>\n",
              "      <th>...</th>\n",
              "      <th>ps_calc_11</th>\n",
              "      <th>ps_calc_12</th>\n",
              "      <th>ps_calc_13</th>\n",
              "      <th>ps_calc_14</th>\n",
              "      <th>ps_calc_15_bin</th>\n",
              "      <th>ps_calc_16_bin</th>\n",
              "      <th>ps_calc_17_bin</th>\n",
              "      <th>ps_calc_18_bin</th>\n",
              "      <th>ps_calc_19_bin</th>\n",
              "      <th>ps_calc_20_bin</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>7</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>9.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>9</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>7</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>13</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>4</td>\n",
              "      <td>9</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>4.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>16</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>17</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 59 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b9011747-06b5-432c-a1d4-8dd20128071c')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-b9011747-06b5-432c-a1d4-8dd20128071c button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-b9011747-06b5-432c-a1d4-8dd20128071c');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-3d6d21e6-15e2-41c9-aa43-c9250a973e0b\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-3d6d21e6-15e2-41c9-aa43-c9250a973e0b')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-3d6d21e6-15e2-41c9-aa43-c9250a973e0b button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df_raw"
            }
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "9ca2a34a",
      "metadata": {
        "id": "9ca2a34a"
      },
      "outputs": [],
      "source": [
        "def create_text_classification_example(row):\n",
        "    PROMPT = (\n",
        "        \"Assess the likelihood of an insurance claim being filed based on the following customer attributes. \"\n",
        "        \"All attributes have been anonymized to protect data confidentiality. \"\n",
        "    )\n",
        "\n",
        "    INPUT_TEXT = \"The client attributes are: \"\n",
        "    features = []\n",
        "\n",
        "    feature_cols = [col for col in df_raw.columns if col not in ['id', 'target']]\n",
        "\n",
        "    for col in feature_cols:\n",
        "        val = row[col] if pd.notna(row[col]) else 'NaN'\n",
        "        features.append(f\"{col}: {val}\")\n",
        "\n",
        "    INPUT_TEXT += \", \".join(features) + \".\"\n",
        "\n",
        "    if \"target\" in row:\n",
        "      LABEL = row['target']\n",
        "    else:\n",
        "      LABEL = None\n",
        "\n",
        "    formatted_instruction = {\n",
        "        \"text\": f\"{PROMPT} {INPUT_TEXT}\",\n",
        "        \"label\": LABEL\n",
        "    }\n",
        "    return formatted_instruction"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bfc710ea",
      "metadata": {
        "id": "bfc710ea"
      },
      "source": [
        "## Pandas to Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "219fdc5f",
      "metadata": {
        "id": "219fdc5f"
      },
      "outputs": [],
      "source": [
        "from datasets import Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "72c8b638",
      "metadata": {
        "id": "72c8b638"
      },
      "outputs": [],
      "source": [
        "def pandas_to_dataset(df):\n",
        "  instruction_data = df.apply(create_text_classification_example, axis=1).tolist()\n",
        "  df_instructions = pd.DataFrame(instruction_data)\n",
        "  hf_dataset = Dataset.from_pandas(df_instructions)\n",
        "  return hf_dataset"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "hf_dataset = pandas_to_dataset(df_raw)\n",
        "hf_dataset_ott = pandas_to_dataset(df_ott)"
      ],
      "metadata": {
        "id": "LUhr320-kve5"
      },
      "id": "LUhr320-kve5",
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "b52e7843",
      "metadata": {
        "id": "b52e7843"
      },
      "source": [
        "# Preprocessing dataset\n",
        "\n",
        "This includes:\n",
        "\n",
        "- Labels mapping;\n",
        "- Prompt engineering;\n",
        "- Data splitting."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fbb0e2c3",
      "metadata": {
        "id": "fbb0e2c3"
      },
      "source": [
        "## Label-to-ID mapping"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "d01b4aea",
      "metadata": {
        "id": "d01b4aea"
      },
      "outputs": [],
      "source": [
        "id2label = {0: \"NO_CLAIM\", 1: \"CLAIM_FILED\"}\n",
        "label2id = {\"NO_CLAIM\": 0, \"CLAIM_FILED\": 1}\n",
        "\n",
        "# labels = dataset[\"train\"].features[\"label\"].names\n",
        "# label2id, id2label = dict(), dict()\n",
        "# for i, label in enumerate(labels):\n",
        "#   label2id[label] = i\n",
        "#   id2label[i] = label"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b38b6ed9",
      "metadata": {
        "id": "b38b6ed9"
      },
      "source": [
        "## Text processor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "961cbfa5",
      "metadata": {
        "id": "961cbfa5"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoTokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "10e97b5c",
      "metadata": {
        "id": "10e97b5c"
      },
      "outputs": [],
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "4c23e9a5",
      "metadata": {
        "id": "4c23e9a5"
      },
      "outputs": [],
      "source": [
        "def preprocess(examples):\n",
        "    tokenized_inputs = tokenizer(examples[\"text\"], truncation=True)\n",
        "    labels = []\n",
        "\n",
        "    for label in examples[\"label\"]:\n",
        "      if label is None:\n",
        "        labels.append(None)\n",
        "      else:\n",
        "        labels.append(int(label))\n",
        "\n",
        "    tokenized_inputs[\"labels\"] = labels\n",
        "    return tokenized_inputs"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6ea3cb39",
      "metadata": {
        "id": "6ea3cb39"
      },
      "source": [
        "## Data splitting\n",
        "\n",
        "Three data splits; 1) train, 2) eval, 2) test."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "hf_dataset = hf_dataset.train_test_split(test_size=0.3)"
      ],
      "metadata": {
        "id": "HZGxI8wRgdbn"
      },
      "id": "HZGxI8wRgdbn",
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hf_dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G4MK83lIu-86",
        "outputId": "3b5bb68d-2c63-4376-db11-d3767d6451be"
      },
      "id": "G4MK83lIu-86",
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['text', 'label'],\n",
              "        num_rows: 113434\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['text', 'label'],\n",
              "        num_rows: 48615\n",
              "    })\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "hf_dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BQYEQPRDgmVJ",
        "outputId": "93206abc-94f5-45f7-ea74-fadb93a235e6"
      },
      "id": "BQYEQPRDgmVJ",
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['text', 'label'],\n",
              "        num_rows: 113434\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['text', 'label'],\n",
              "        num_rows: 48615\n",
              "    })\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = hf_dataset[\"train\"]\n",
        "val_data = hf_dataset[\"test\"]\n",
        "\n",
        "val_data_split = val_data.train_test_split(test_size=0.3)\n",
        "val_data = val_data_split[\"train\"]\n",
        "test_data = val_data_split[\"test\"]"
      ],
      "metadata": {
        "id": "x8MLt99egkjG"
      },
      "id": "x8MLt99egkjG",
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "13b83308",
      "metadata": {
        "id": "13b83308"
      },
      "outputs": [],
      "source": [
        "train_data.set_transform(preprocess)\n",
        "val_data.set_transform(preprocess)\n",
        "test_data.set_transform(preprocess)\n",
        "hf_dataset_ott.set_transform(preprocess)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e727013c",
      "metadata": {
        "id": "e727013c"
      },
      "source": [
        "# Model _tunable_ hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "id": "8fa20792",
      "metadata": {
        "id": "8fa20792"
      },
      "outputs": [],
      "source": [
        "def print_trainable_parameters(model):\n",
        "  trainable_params = 0\n",
        "  all_param = 0\n",
        "  for _, param in model.named_parameters():\n",
        "      all_param += param.numel()\n",
        "      if param.requires_grad:\n",
        "          trainable_params += param.numel()\n",
        "  logger.info(\n",
        "      f\"trainable params: {trainable_params} || all params: {all_param} || trainable%: {100 * trainable_params / all_param:.2f}\"\n",
        "  )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "id": "64cc2c77",
      "metadata": {
        "id": "64cc2c77"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoModelForSequenceClassification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "id": "fefdacde",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fefdacde",
        "outputId": "581ee0b1-6282-490d-8831-a2f7eba9d35c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google-bert/bert-large-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "model = AutoModelForSequenceClassification.from_pretrained(\n",
        "    model_checkpoint,\n",
        "    num_labels=2,\n",
        "    id2label=id2label,\n",
        "    label2id=label2id,\n",
        "    ignore_mismatched_sizes=True,\n",
        "    problem_type=\"single_label_classification\", # Explicitly set for binary classification\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "id": "414dbe42",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "414dbe42",
        "outputId": "b5255a93-d9a4-44c6-c233-310423b43e34"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-11-20 19:30:09,732 - INFO - trainable params: 335143938 || all params: 335143938 || trainable%: 100.00\n"
          ]
        }
      ],
      "source": [
        "print_trainable_parameters(model)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6c4383a4",
      "metadata": {
        "id": "6c4383a4"
      },
      "source": [
        "# Low-Rank Adaptation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "id": "f8532d4f",
      "metadata": {
        "id": "f8532d4f"
      },
      "outputs": [],
      "source": [
        "from peft import LoraConfig, get_peft_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "id": "2fe0f2d8",
      "metadata": {
        "id": "2fe0f2d8"
      },
      "outputs": [],
      "source": [
        "lora_config = LoraConfig(\n",
        "    r=32,\n",
        "    lora_alpha=16,\n",
        "    target_modules=[\"query\", \"value\"],\n",
        "    lora_dropout=0.1,\n",
        "    bias=\"none\",\n",
        "    task_type=\"SEQ_CLS\",\n",
        "    modules_to_save=[\"classifier\"],\n",
        ")\n",
        "\n",
        "lora_model = get_peft_model(model, lora_config)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "id": "f968f3da",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f968f3da",
        "outputId": "98af152a-d63f-4335-e17d-e4ec9397079b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-11-20 19:30:10,332 - INFO - trainable params: 3147778 || all params: 338291716 || trainable%: 0.93\n"
          ]
        }
      ],
      "source": [
        "print_trainable_parameters(lora_model)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e60ed0a5",
      "metadata": {
        "id": "e60ed0a5"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "id": "16501dda",
      "metadata": {
        "id": "16501dda"
      },
      "outputs": [],
      "source": [
        "from transformers import TrainingArguments"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "id": "5abf96c6",
      "metadata": {
        "id": "5abf96c6"
      },
      "outputs": [],
      "source": [
        "import datetime"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "id": "93864b16",
      "metadata": {
        "id": "93864b16"
      },
      "outputs": [],
      "source": [
        "model_name = model_checkpoint.split(\"/\")[-1]\n",
        "batch_size = 64\n",
        "learning_rate = 5e-3\n",
        "num_train_epochs = 5\n",
        "logging_steps = 10\n",
        "\n",
        "timestamp = datetime.datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
        "run_name = f\"{model_name}-l{learning_rate}_b{batch_size}_e{num_train_epochs}_finetuned-lora-{dataset_id}-{timestamp}\"\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "  run_name,\n",
        "  remove_unused_columns=False,\n",
        "  eval_strategy=\"epoch\",\n",
        "  save_strategy=\"epoch\",\n",
        "  learning_rate=learning_rate,\n",
        "  per_device_train_batch_size=batch_size,\n",
        "  gradient_accumulation_steps=4,\n",
        "  per_device_eval_batch_size=batch_size,\n",
        "  fp16=True,\n",
        "  num_train_epochs=num_train_epochs,\n",
        "  logging_steps=logging_steps,\n",
        "  load_best_model_at_end=True,\n",
        "  metric_for_best_model=\"accuracy\",\n",
        "  push_to_hub=True,\n",
        "  label_names=[\"labels\"],\n",
        "  run_name=run_name,\n",
        "  report_to=[\"wandb\"]\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e4b7ac0d",
      "metadata": {
        "id": "e4b7ac0d"
      },
      "source": [
        "## Evaluation metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "id": "7afe7fe4",
      "metadata": {
        "id": "7afe7fe4"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import evaluate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "id": "5ae8052f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "bb471ee38e144922b37ba76b43834d98",
            "1fbb8b946a8942299ca56e8a4e7e6341",
            "127176db07fc47a295aa13cfad68f709",
            "1a03644af5984c2eb3f1614cc4055074",
            "c463776f85ba4736a6782982005dc15a",
            "df3cb01ea6ff4836acab096ca42b269b",
            "87de711f5945436fa1d8eefcda16f452",
            "861bd99f894a4a08ab458b2cb07ebda1",
            "ac7826610d1a41a187ab28de5503a68c",
            "702c87e0ba4e44ab8a08e6ddf0e54910",
            "0110a3dbd97a48dea6f8faa6585f1a8b"
          ]
        },
        "id": "5ae8052f",
        "outputId": "1c76333f-a85e-490f-9a6f-0152a5ca8076"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading builder script: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "bb471ee38e144922b37ba76b43834d98"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "metric = evaluate.load(\"accuracy\")\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "  \"\"\"Computes accuracy on a batch of predictions\"\"\"\n",
        "  predictions = np.argmax(eval_pred.predictions, axis=1)\n",
        "  return metric.compute(predictions=predictions, references=eval_pred.label_ids)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "90bd8f13",
      "metadata": {
        "id": "90bd8f13"
      },
      "source": [
        "## Data collaction function\n",
        "\n",
        "> A collation function is used by Trainer to gather a batch of training and evaluation examples and prepare them in a format that is acceptable by the underlying model. [Read more](https://huggingface.co/docs/transformers/main/en/main_classes/trainer#transformers.Trainer)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "id": "c765a24f",
      "metadata": {
        "id": "c765a24f"
      },
      "outputs": [],
      "source": [
        "from transformers import DataCollatorWithPadding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "id": "8affa1c8",
      "metadata": {
        "id": "8affa1c8"
      },
      "outputs": [],
      "source": [
        "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0768568f",
      "metadata": {
        "id": "0768568f"
      },
      "source": [
        "## Training steps"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "id": "6e92fd56",
      "metadata": {
        "id": "6e92fd56"
      },
      "outputs": [],
      "source": [
        "from transformers import Trainer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "id": "b7e97453",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 460
        },
        "id": "b7e97453",
        "outputId": "686b63ff-52ed-4b91-bfc6-429564a9050b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-1417688586.py:1: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = Trainer(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting LoRA Fine-tuning for Text Classification...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.22.3"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20251120_193015-s1631kds</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/emmanuel-company/huggingface/runs/s1631kds' target=\"_blank\">bert-large-uncased-l0.005_b64_e5_finetuned-lora-porto-seguro-2025-11-20_19-30-10</a></strong> to <a href='https://wandb.ai/emmanuel-company/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/emmanuel-company/huggingface' target=\"_blank\">https://wandb.ai/emmanuel-company/huggingface</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/emmanuel-company/huggingface/runs/s1631kds' target=\"_blank\">https://wandb.ai/emmanuel-company/huggingface/runs/s1631kds</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='2220' max='2220' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [2220/2220 1:17:43, Epoch 5/5]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.169300</td>\n",
              "      <td>0.206221</td>\n",
              "      <td>0.962151</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.152800</td>\n",
              "      <td>0.171469</td>\n",
              "      <td>0.962151</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.181100</td>\n",
              "      <td>0.163459</td>\n",
              "      <td>0.962151</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.156100</td>\n",
              "      <td>0.167533</td>\n",
              "      <td>0.962151</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.149400</td>\n",
              "      <td>0.162579</td>\n",
              "      <td>0.962151</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=2220, training_loss=0.16823271985526558, metrics={'train_runtime': 4668.2101, 'train_samples_per_second': 121.496, 'train_steps_per_second': 0.476, 'total_flos': 5.340480305013965e+17, 'train_loss': 0.16823271985526558, 'epoch': 5.0})"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ],
      "source": [
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_data,\n",
        "    eval_dataset=val_data,\n",
        "    tokenizer=tokenizer,\n",
        "    data_collator=data_collator,\n",
        "    compute_metrics=compute_metrics,\n",
        ")\n",
        "\n",
        "logger.info(\"Starting LoRA Fine-tuning for Text Classification...\")\n",
        "trainer.train()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9133fe0a",
      "metadata": {
        "id": "9133fe0a"
      },
      "source": [
        "# Evaluate metrics on test - unseen - dataset\n",
        "\n",
        "Results from training, system usage and evaluation will be in the dashboard of Weights and Biases. [Read more](https://wandb.ai/emmanuel-company/huggingface/runs/ppf670zf?nw=nwuseryveemmanuel)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "id": "fb4076b2",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "id": "fb4076b2",
        "outputId": "81770857-4100-4303-eb9c-ae092ef1502b"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='228' max='228' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [228/228 00:47]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'eval_loss': 0.20511698722839355,\n",
              " 'eval_accuracy': 0.9623585875899897,\n",
              " 'eval_runtime': 47.6552,\n",
              " 'eval_samples_per_second': 306.053,\n",
              " 'eval_steps_per_second': 4.784,\n",
              " 'epoch': 5.0}"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ],
      "source": [
        "trainer.evaluate(test_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "id": "7d5d3115",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 739
        },
        "id": "7d5d3115",
        "outputId": "5fcc4b5e-8bca-44e0-c3af-40c289b3a067"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>▁▁▁▁▁█</td></tr><tr><td>eval/loss</td><td>█▂▁▂▁█</td></tr><tr><td>eval/runtime</td><td>█████▁</td></tr><tr><td>eval/samples_per_second</td><td>▃▄▁▄▅█</td></tr><tr><td>eval/steps_per_second</td><td>▃▄▁▄▅█</td></tr><tr><td>train/epoch</td><td>▁▁▁▂▂▂▂▂▂▂▂▃▃▃▃▄▄▄▄▄▄▄▅▅▅▆▆▆▆▆▇▇▇▇▇▇▇███</td></tr><tr><td>train/global_step</td><td>▁▁▁▁▁▂▂▂▂▂▃▃▃▃▃▄▄▄▄▅▅▅▅▆▆▆▆▆▆▆▇▇▇▇▇█████</td></tr><tr><td>train/grad_norm</td><td>█▂▂▁▃▂▂▂▁▁▁▂▁▁▁▂▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▁▁▁▁▁</td></tr><tr><td>train/learning_rate</td><td>███▇▇▇▇▇▇▆▆▆▅▅▅▅▅▅▅▅▅▄▄▄▄▄▄▄▃▃▃▃▃▃▃▂▂▂▁▁</td></tr><tr><td>train/loss</td><td>█▆▄▄▆▃▄▅▆▄▅▅▃▅▆▃▇▃▅▆▄▃▆▃▅▅▃▄▅▂▁▃▂▇▅▄▄▅▃▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>0.96236</td></tr><tr><td>eval/loss</td><td>0.20512</td></tr><tr><td>eval/runtime</td><td>47.6552</td></tr><tr><td>eval/samples_per_second</td><td>306.053</td></tr><tr><td>eval/steps_per_second</td><td>4.784</td></tr><tr><td>total_flos</td><td>5.340480305013965e+17</td></tr><tr><td>train/epoch</td><td>5</td></tr><tr><td>train/global_step</td><td>2220</td></tr><tr><td>train/grad_norm</td><td>0.56639</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>+5</td><td>...</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">bert-large-uncased-l0.005_b64_e5_finetuned-lora-porto-seguro-2025-11-20_19-30-10</strong> at: <a href='https://wandb.ai/emmanuel-company/huggingface/runs/s1631kds' target=\"_blank\">https://wandb.ai/emmanuel-company/huggingface/runs/s1631kds</a><br> View project at: <a href='https://wandb.ai/emmanuel-company/huggingface' target=\"_blank\">https://wandb.ai/emmanuel-company/huggingface</a><br>Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20251120_193015-s1631kds/logs</code>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "wandb.finish()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    },
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "bae0d469",
        "fbb0e2c3"
      ],
      "machine_shape": "hm",
      "gpuType": "A100",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}